{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a094cebc",
   "metadata": {},
   "source": [
    "\n",
    "# Capstone Project \n",
    "\n",
    "# Author : Hamidreza Salahi\n",
    "\n",
    "# Notebook : 4\n",
    "\n",
    "# Models Building"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6da50feb",
   "metadata": {},
   "source": [
    "After completing EDA and having a clean dataset to work with, the next step is to do some baseline modeling. The goal of this notebook is to find the best classification model amongst *Logistic Regression, SVC, Decision tree* in terms of their accuracy using pipeline and grid search."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6caf30f9",
   "metadata": {
    "id": "5BQ7jdWyVTzo"
   },
   "source": [
    "## Contents:\n",
    "* [Artificial Neural Networks (ANNs)](#Artificial-Neural-Networks-(ANNs))\n",
    "* [XGBoost Classifier](#XGBoost-Classifier)\n",
    "* [Random Forest Classifier](#Random-Forest-Classifier)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5fac4a00",
   "metadata": {
    "id": "7ZjuapQJVTzp"
   },
   "outputs": [],
   "source": [
    "# Importing libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "78c0730d",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>loan_status</th>\n",
       "      <th>last_fico_avg</th>\n",
       "      <th>int_rate</th>\n",
       "      <th>term</th>\n",
       "      <th>fico_avg</th>\n",
       "      <th>acc_open_past_24mths</th>\n",
       "      <th>funded_amnt</th>\n",
       "      <th>loan_amnt</th>\n",
       "      <th>tot_hi_cred_lim</th>\n",
       "      <th>dti</th>\n",
       "      <th>...</th>\n",
       "      <th>home_improvement</th>\n",
       "      <th>house</th>\n",
       "      <th>major_purchase</th>\n",
       "      <th>medical</th>\n",
       "      <th>moving</th>\n",
       "      <th>other</th>\n",
       "      <th>renewable_energy</th>\n",
       "      <th>small_business</th>\n",
       "      <th>vacation</th>\n",
       "      <th>wedding</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>697.0</td>\n",
       "      <td>20.55</td>\n",
       "      <td>60</td>\n",
       "      <td>702.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>32025.0</td>\n",
       "      <td>32025.0</td>\n",
       "      <td>210073.0</td>\n",
       "      <td>39.97</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>682.0</td>\n",
       "      <td>9.99</td>\n",
       "      <td>36</td>\n",
       "      <td>687.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>11200.0</td>\n",
       "      <td>11200.0</td>\n",
       "      <td>97239.0</td>\n",
       "      <td>28.19</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>692.0</td>\n",
       "      <td>15.05</td>\n",
       "      <td>36</td>\n",
       "      <td>662.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>20000.0</td>\n",
       "      <td>20000.0</td>\n",
       "      <td>32716.0</td>\n",
       "      <td>19.01</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>507.0</td>\n",
       "      <td>11.53</td>\n",
       "      <td>36</td>\n",
       "      <td>672.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>10000.0</td>\n",
       "      <td>10000.0</td>\n",
       "      <td>14200.0</td>\n",
       "      <td>3.13</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>507.0</td>\n",
       "      <td>17.27</td>\n",
       "      <td>60</td>\n",
       "      <td>662.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>11050.0</td>\n",
       "      <td>11050.0</td>\n",
       "      <td>245250.0</td>\n",
       "      <td>8.50</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 79 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   loan_status  last_fico_avg  int_rate  term  fico_avg  acc_open_past_24mths  \\\n",
       "0            0          697.0     20.55    60     702.0                   7.0   \n",
       "1            0          682.0      9.99    36     687.0                   4.0   \n",
       "2            0          692.0     15.05    36     662.0                   2.0   \n",
       "3            1          507.0     11.53    36     672.0                   2.0   \n",
       "4            1          507.0     17.27    60     662.0                   5.0   \n",
       "\n",
       "   funded_amnt  loan_amnt  tot_hi_cred_lim    dti  ...  home_improvement  \\\n",
       "0      32025.0    32025.0         210073.0  39.97  ...               0.0   \n",
       "1      11200.0    11200.0          97239.0  28.19  ...               0.0   \n",
       "2      20000.0    20000.0          32716.0  19.01  ...               0.0   \n",
       "3      10000.0    10000.0          14200.0   3.13  ...               0.0   \n",
       "4      11050.0    11050.0         245250.0   8.50  ...               0.0   \n",
       "\n",
       "   house  major_purchase  medical  moving  other  renewable_energy  \\\n",
       "0    0.0             0.0      0.0     0.0    0.0               0.0   \n",
       "1    0.0             0.0      0.0     0.0    0.0               0.0   \n",
       "2    0.0             0.0      0.0     0.0    0.0               0.0   \n",
       "3    0.0             0.0      0.0     0.0    0.0               0.0   \n",
       "4    0.0             0.0      0.0     0.0    0.0               0.0   \n",
       "\n",
       "   small_business  vacation  wedding  \n",
       "0             0.0       0.0      0.0  \n",
       "1             0.0       0.0      0.0  \n",
       "2             0.0       0.0      0.0  \n",
       "3             0.0       0.0      0.0  \n",
       "4             0.0       0.0      0.0  \n",
       "\n",
       "[5 rows x 79 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Importing clean data\n",
    "loan_df = pd.read_csv('C:\\\\Users\\\\hamid\\\\Desktop\\\\Capstone\\\\Data\\\\loan_sample_after_EDA.csv')\n",
    "\n",
    "loan_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "77a2a0f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(228958, 79)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loan_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cd465be",
   "metadata": {},
   "source": [
    "### Test-Train Split"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "472ad495",
   "metadata": {},
   "source": [
    "The first step in modeling is to seperate the dependent, y = `loan_status`, from all the independent variables, X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "86d14b23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seperating the dependent variable (y) from the independent variables (X)\n",
    "X = loan_df.drop(columns='loan_status')\n",
    "y = loan_df['loan_status']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b27ba60",
   "metadata": {},
   "source": [
    "Next step is to split the dataset into Training, Validation and Test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6aa3d803",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import train_test_split\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, \n",
    "                                                      y, \n",
    "                                                      test_size = 0.2, \n",
    "                                                      random_state = 15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5dd3b3a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The shape of the X_train dataframe is: (183166, 78).\n",
      "The shape of the X_test dataframe is: (45792, 78).\n",
      "\n",
      "The shape of the y_train dataframe is: (183166,).\n",
      "The shape of the y_test dataframe is: (45792,).\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# check dataframes shapes\n",
    "print(f\"The shape of the X_train dataframe is: {X_train.shape}.\")\n",
    "print(f\"The shape of the X_test dataframe is: {X_test.shape}.\\n\")\n",
    "print(f\"The shape of the y_train dataframe is: {y_train.shape}.\")\n",
    "print(f\"The shape of the y_test dataframe is: {y_test.shape}.\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16ebebba",
   "metadata": {},
   "source": [
    "### Scaling Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9c3b5f5",
   "metadata": {},
   "source": [
    "Now I am going to apply MinMaxScaler to the dataset. It is noted that the scaling is applied *after* train-test split to avoid data leakage i.e., the test data is not supposed to be exposed to MinMaxScaling at first. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c039237c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "# apply MinMaxScaler()\n",
    "# instantiate the model\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "# fit the model\n",
    "scaler = scaler.fit(X_train)\n",
    "\n",
    "# transform\n",
    "X_train_scaled= scaler.transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ed77ecd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3ea132b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b19b9cc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c0a373d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hamid\\anaconda3\\envs\\XGB_ANN\\lib\\site-packages\\xgboost\\compat.py:93: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  from pandas import MultiIndex, Int64Index\n"
     ]
    }
   ],
   "source": [
    "from scipy import stats \n",
    "\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, confusion_matrix, classification_report, \n",
    "    roc_auc_score, roc_curve, auc,\n",
    "    plot_confusion_matrix, plot_roc_curve\n",
    ")\n",
    "\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.layers import Dense, Dropout, BatchNormalization \n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.metrics import AUC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "aa9f5fb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_nn(true, pred, train=True):\n",
    "    if train:\n",
    "        clf_report = pd.DataFrame(classification_report(true, pred, output_dict=True))\n",
    "        print(\"Train Result:\\n================================================\")\n",
    "        print(f\"Accuracy Score: {accuracy_score(true, pred) * 100:.2f}%\")\n",
    "        print(\"_______________________________________________\")\n",
    "        print(f\"CLASSIFICATION REPORT:\\n{clf_report}\")\n",
    "        print(\"_______________________________________________\")\n",
    "        print(f\"Confusion Matrix: \\n {confusion_matrix(true, pred)}\\n\")\n",
    "        \n",
    "    elif train==False:\n",
    "        clf_report = pd.DataFrame(classification_report(true, pred, output_dict=True))\n",
    "        print(\"Test Result:\\n================================================\")        \n",
    "        print(f\"Accuracy Score: {accuracy_score(true, pred) * 100:.2f}%\")\n",
    "        print(\"_______________________________________________\")\n",
    "        print(f\"CLASSIFICATION REPORT:\\n{clf_report}\")\n",
    "        print(\"_______________________________________________\")\n",
    "        print(f\"Confusion Matrix: \\n {confusion_matrix(true, pred)}\\n\")\n",
    "        \n",
    "def plot_learning_evolution(r):\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    \n",
    "    plt.subplot(2, 2, 1)\n",
    "    plt.plot(r.history['loss'], label='Loss')\n",
    "    plt.plot(r.history['val_loss'], label='val_Loss')\n",
    "    plt.title('Loss evolution during trainig')\n",
    "    plt.legend()\n",
    "\n",
    "    plt.subplot(2, 2, 2)\n",
    "    plt.plot(r.history['AUC'], label='AUC')\n",
    "    plt.plot(r.history['val_AUC'], label='val_AUC')\n",
    "    plt.title('AUC score evolution during trainig')\n",
    "    plt.legend();\n",
    "\n",
    "def nn_model(num_columns, num_labels, hidden_units, dropout_rates, learning_rate):\n",
    "    inp = tf.keras.layers.Input(shape=(num_columns, ))\n",
    "    x = BatchNormalization()(inp)\n",
    "    x = Dropout(dropout_rates[0])(x)\n",
    "    for i in range(len(hidden_units)):\n",
    "        x = Dense(hidden_units[i], activation='relu')(x)\n",
    "        x = BatchNormalization()(x)\n",
    "        x = Dropout(dropout_rates[i + 1])(x)\n",
    "    x = Dense(num_labels, activation='sigmoid')(x)\n",
    "  \n",
    "    model = Model(inputs=inp, outputs=x)\n",
    "    model.compile(optimizer=Adam(learning_rate), loss='binary_crossentropy', metrics=[AUC(name='AUC')])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ee9d975e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "5724/5724 [==============================] - 18s 3ms/step - loss: 0.3610 - AUC: 0.9190 - val_loss: 0.2877 - val_AUC: 0.9484\n",
      "Epoch 2/20\n",
      "5724/5724 [==============================] - 18s 3ms/step - loss: 0.3456 - AUC: 0.9257 - val_loss: 0.2891 - val_AUC: 0.9494\n",
      "Epoch 3/20\n",
      "5724/5724 [==============================] - 19s 3ms/step - loss: 0.3442 - AUC: 0.9264 - val_loss: 0.2873 - val_AUC: 0.9496\n",
      "Epoch 4/20\n",
      "5724/5724 [==============================] - 18s 3ms/step - loss: 0.3415 - AUC: 0.9276 - val_loss: 0.2848 - val_AUC: 0.9505\n",
      "Epoch 5/20\n",
      "5724/5724 [==============================] - 19s 3ms/step - loss: 0.3399 - AUC: 0.9283 - val_loss: 0.2834 - val_AUC: 0.9503\n",
      "Epoch 6/20\n",
      "5724/5724 [==============================] - 17s 3ms/step - loss: 0.3389 - AUC: 0.9287 - val_loss: 0.2873 - val_AUC: 0.9502\n",
      "Epoch 7/20\n",
      "5724/5724 [==============================] - 17s 3ms/step - loss: 0.3385 - AUC: 0.9288 - val_loss: 0.2871 - val_AUC: 0.9509\n",
      "Epoch 8/20\n",
      "5724/5724 [==============================] - 18s 3ms/step - loss: 0.3379 - AUC: 0.9292 - val_loss: 0.2817 - val_AUC: 0.9509\n",
      "Epoch 9/20\n",
      "5724/5724 [==============================] - 17s 3ms/step - loss: 0.3371 - AUC: 0.9295 - val_loss: 0.2873 - val_AUC: 0.9506\n",
      "Epoch 10/20\n",
      "5724/5724 [==============================] - 18s 3ms/step - loss: 0.3358 - AUC: 0.9300 - val_loss: 0.2836 - val_AUC: 0.9504\n",
      "Epoch 11/20\n",
      "5724/5724 [==============================] - 18s 3ms/step - loss: 0.3356 - AUC: 0.9301 - val_loss: 0.2825 - val_AUC: 0.9505\n",
      "Epoch 12/20\n",
      "5724/5724 [==============================] - 18s 3ms/step - loss: 0.3348 - AUC: 0.9306 - val_loss: 0.2862 - val_AUC: 0.9500\n",
      "Epoch 13/20\n",
      "5724/5724 [==============================] - 18s 3ms/step - loss: 0.3343 - AUC: 0.9307 - val_loss: 0.2829 - val_AUC: 0.9504\n",
      "Epoch 14/20\n",
      "5724/5724 [==============================] - 18s 3ms/step - loss: 0.3332 - AUC: 0.9312 - val_loss: 0.2878 - val_AUC: 0.9504\n",
      "Epoch 15/20\n",
      "5724/5724 [==============================] - 18s 3ms/step - loss: 0.3326 - AUC: 0.9314 - val_loss: 0.2854 - val_AUC: 0.9507\n",
      "Epoch 16/20\n",
      "5724/5724 [==============================] - 18s 3ms/step - loss: 0.3312 - AUC: 0.9321 - val_loss: 0.2852 - val_AUC: 0.9500\n",
      "Epoch 17/20\n",
      "5724/5724 [==============================] - 18s 3ms/step - loss: 0.3309 - AUC: 0.9321 - val_loss: 0.2834 - val_AUC: 0.9502\n",
      "Epoch 18/20\n",
      "5724/5724 [==============================] - 18s 3ms/step - loss: 0.3308 - AUC: 0.9322 - val_loss: 0.2827 - val_AUC: 0.9505\n",
      "Epoch 19/20\n",
      "5724/5724 [==============================] - 18s 3ms/step - loss: 0.3302 - AUC: 0.9324 - val_loss: 0.2827 - val_AUC: 0.9501\n",
      "Epoch 20/20\n",
      "5724/5724 [==============================] - 18s 3ms/step - loss: 0.3295 - AUC: 0.9327 - val_loss: 0.2827 - val_AUC: 0.9505\n"
     ]
    }
   ],
   "source": [
    "num_columns = X_train_scaled.shape[1]\n",
    "num_labels = 1\n",
    "hidden_units = [150, 150, 150]\n",
    "dropout_rates = [0.1, 0, 0.1, 0]\n",
    "learning_rate = 1e-3\n",
    "\n",
    "\n",
    "model = nn_model(\n",
    "    num_columns=num_columns, \n",
    "    num_labels=num_labels,\n",
    "    hidden_units=hidden_units,\n",
    "    dropout_rates=dropout_rates,\n",
    "    learning_rate=learning_rate\n",
    ")\n",
    "r = model.fit(\n",
    "    X_train_scaled, y_train,\n",
    "    validation_data=(X_test_scaled, y_test),\n",
    "    epochs=20,\n",
    "    batch_size=32\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1c630d9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Result:\n",
      "================================================\n",
      "Accuracy Score: 88.67%\n",
      "_______________________________________________\n",
      "CLASSIFICATION REPORT:\n",
      "                      0             1  accuracy     macro avg  weighted avg\n",
      "precision      0.912080      0.862646  0.886749      0.887363      0.888109\n",
      "recall         0.863357      0.911596  0.886749      0.887477      0.886749\n",
      "f1-score       0.887050      0.886446  0.886749      0.886748      0.886757\n",
      "support    23587.000000  22205.000000  0.886749  45792.000000  45792.000000\n",
      "_______________________________________________\n",
      "Confusion Matrix: \n",
      " [[20364  3223]\n",
      " [ 1963 20242]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_test_pred = model.predict(X_test_scaled)\n",
    "evaluate_nn(y_test, y_test_pred.round(), train=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6acb600b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b6ff1f57",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_score(true, pred, train=True):\n",
    "    if train:\n",
    "        clf_report = pd.DataFrame(classification_report(true, pred, output_dict=True))\n",
    "        print(\"Train Result:\\n================================================\")\n",
    "        print(f\"Accuracy Score: {accuracy_score(true, pred) * 100:.2f}%\")\n",
    "        print(\"_______________________________________________\")\n",
    "        print(f\"CLASSIFICATION REPORT:\\n{clf_report}\")\n",
    "        print(\"_______________________________________________\")\n",
    "        print(f\"Confusion Matrix: \\n {confusion_matrix(true, pred)}\\n\")\n",
    "        \n",
    "    elif train==False:\n",
    "        clf_report = pd.DataFrame(classification_report(true, pred, output_dict=True))\n",
    "        print(\"Test Result:\\n================================================\")        \n",
    "        print(f\"Accuracy Score: {accuracy_score(true, pred) * 100:.2f}%\")\n",
    "        print(\"_______________________________________________\")\n",
    "        print(f\"CLASSIFICATION REPORT:\\n{clf_report}\")\n",
    "        print(\"_______________________________________________\")\n",
    "        print(f\"Confusion Matrix: \\n {confusion_matrix(true, pred)}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1af954f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[23:34:51] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { use_label_encoder } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "Test Result:\n",
      "================================================\n",
      "Accuracy Score: 88.95%\n",
      "_______________________________________________\n",
      "CLASSIFICATION REPORT:\n",
      "                      0             1  accuracy     macro avg  weighted avg\n",
      "precision      0.912859      0.866978  0.889457      0.889919      0.890611\n",
      "recall         0.868275      0.911957  0.889457      0.890116      0.889457\n",
      "f1-score       0.890009      0.888899  0.889457      0.889454      0.889471\n",
      "support    23587.000000  22205.000000  0.889457  45792.000000  45792.000000\n",
      "_______________________________________________\n",
      "Confusion Matrix: \n",
      " [[20480  3107]\n",
      " [ 1955 20250]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "xgb_clf = XGBClassifier(use_label_encoder=False)\n",
    "# xgb_cv = RandomizedSearchCV(\n",
    "#     xgb_clf, param_grid, cv=3, n_iter=60, \n",
    "#     scoring='roc_auc', n_jobs=-1, verbose=1\n",
    "# )\n",
    "# xgb_cv.fit(X_train, y_train)\n",
    "\n",
    "# best_params = xgb_cv.best_params_\n",
    "# best_params['tree_method'] = 'gpu_hist'\n",
    "# # best_params = {'n_estimators': 50, 'tree_method': 'gpu_hist'}\n",
    "# print(f\"Best Parameters: {best_params}\")\n",
    "\n",
    "# xgb_clf = XGBClassifier(**best_params)\n",
    "xgb_clf.fit(X_train_scaled, y_train)\n",
    "\n",
    "y_test_pred = xgb_clf.predict(X_test_scaled)\n",
    "\n",
    "print_score(y_test, y_test_pred, train=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a1dce41",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb07289c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d13e9a8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Result:\n",
      "================================================\n",
      "Accuracy Score: 100.00%\n",
      "_______________________________________________\n",
      "CLASSIFICATION REPORT:\n",
      "                 0        1  accuracy  macro avg  weighted avg\n",
      "precision      1.0      1.0       1.0        1.0           1.0\n",
      "recall         1.0      1.0       1.0        1.0           1.0\n",
      "f1-score       1.0      1.0       1.0        1.0           1.0\n",
      "support    94203.0  88963.0       1.0   183166.0      183166.0\n",
      "_______________________________________________\n",
      "Confusion Matrix: \n",
      " [[94203     0]\n",
      " [    0 88963]]\n",
      "\n",
      "Test Result:\n",
      "================================================\n",
      "Accuracy Score: 88.92%\n",
      "_______________________________________________\n",
      "CLASSIFICATION REPORT:\n",
      "                      0             1  accuracy     macro avg  weighted avg\n",
      "precision      0.914287      0.865245  0.889173      0.889766      0.890506\n",
      "recall         0.866028      0.913758  0.889173      0.889893      0.889173\n",
      "f1-score       0.889503      0.888840  0.889173      0.889172      0.889182\n",
      "support    23587.000000  22205.000000  0.889173  45792.000000  45792.000000\n",
      "_______________________________________________\n",
      "Confusion Matrix: \n",
      " [[20427  3160]\n",
      " [ 1915 20290]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "rf_clf = RandomForestClassifier(n_estimators=100)\n",
    "# rf_cv = RandomizedSearchCV(\n",
    "#     rf_clf, param_grid, cv=3, n_iter=60, \n",
    "#     scoring='roc_auc', n_jobs=-1, verbose=1\n",
    "# )\n",
    "# rf_cv.fit(X_train, y_train)\n",
    "# best_params = rf_cv.best_params_\n",
    "# print(f\"Best Parameters: {best_params}\")\n",
    "# rf_clf = RandomForestClassifier(**best_params)\n",
    "rf_clf.fit(X_train, y_train)\n",
    "\n",
    "y_train_pred = rf_clf.predict(X_train_scaled)\n",
    "y_test_pred = rf_clf.predict(X_test_scaled)\n",
    "\n",
    "print_score(y_train, y_train_pred, train=True)\n",
    "print_score(y_test, y_test_pred, train=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a6b4680",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "XGB_ANN",
   "language": "python",
   "name": "xgb_ann"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

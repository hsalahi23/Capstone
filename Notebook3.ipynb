{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a094cebc",
   "metadata": {},
   "source": [
    "\n",
    "# Capstone Project \n",
    "\n",
    "# Author : Hamidreza Salahi\n",
    "\n",
    "# Notebook : 3\n",
    "\n",
    "# Baseline models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6da50feb",
   "metadata": {},
   "source": [
    "After completing EDA and having a clean dataset to work with, the next step is to do some baseline modeling. The goal of this notebook is to find the best classification model amongst *Logistic Regression, SVC, Decision tree* in terms of their accuracy using pipeline and grid search."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6caf30f9",
   "metadata": {
    "id": "5BQ7jdWyVTzo"
   },
   "source": [
    "## Contents:\n",
    "* [Train-Test Split](#Train-Test-Split)\n",
    "* [Scaling Data](#Scaling-Data)\n",
    "* [Pipeline and Gridsearch](#Pipeline-and-Gridsearch)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5fac4a00",
   "metadata": {
    "id": "7ZjuapQJVTzp"
   },
   "outputs": [],
   "source": [
    "# Importing libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "78c0730d",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>loan_status</th>\n",
       "      <th>last_fico_avg</th>\n",
       "      <th>int_rate</th>\n",
       "      <th>term</th>\n",
       "      <th>fico_avg</th>\n",
       "      <th>acc_open_past_24mths</th>\n",
       "      <th>funded_amnt</th>\n",
       "      <th>loan_amnt</th>\n",
       "      <th>tot_hi_cred_lim</th>\n",
       "      <th>dti</th>\n",
       "      <th>...</th>\n",
       "      <th>home_improvement</th>\n",
       "      <th>house</th>\n",
       "      <th>major_purchase</th>\n",
       "      <th>medical</th>\n",
       "      <th>moving</th>\n",
       "      <th>other</th>\n",
       "      <th>renewable_energy</th>\n",
       "      <th>small_business</th>\n",
       "      <th>vacation</th>\n",
       "      <th>wedding</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>697.0</td>\n",
       "      <td>20.55</td>\n",
       "      <td>60</td>\n",
       "      <td>702.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>32025.0</td>\n",
       "      <td>32025.0</td>\n",
       "      <td>210073.0</td>\n",
       "      <td>39.97</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>682.0</td>\n",
       "      <td>9.99</td>\n",
       "      <td>36</td>\n",
       "      <td>687.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>11200.0</td>\n",
       "      <td>11200.0</td>\n",
       "      <td>97239.0</td>\n",
       "      <td>28.19</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>692.0</td>\n",
       "      <td>15.05</td>\n",
       "      <td>36</td>\n",
       "      <td>662.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>20000.0</td>\n",
       "      <td>20000.0</td>\n",
       "      <td>32716.0</td>\n",
       "      <td>19.01</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>507.0</td>\n",
       "      <td>11.53</td>\n",
       "      <td>36</td>\n",
       "      <td>672.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>10000.0</td>\n",
       "      <td>10000.0</td>\n",
       "      <td>14200.0</td>\n",
       "      <td>3.13</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>507.0</td>\n",
       "      <td>17.27</td>\n",
       "      <td>60</td>\n",
       "      <td>662.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>11050.0</td>\n",
       "      <td>11050.0</td>\n",
       "      <td>245250.0</td>\n",
       "      <td>8.50</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 79 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   loan_status  last_fico_avg  int_rate  term  fico_avg  acc_open_past_24mths  \\\n",
       "0            0          697.0     20.55    60     702.0                   7.0   \n",
       "1            0          682.0      9.99    36     687.0                   4.0   \n",
       "2            0          692.0     15.05    36     662.0                   2.0   \n",
       "3            1          507.0     11.53    36     672.0                   2.0   \n",
       "4            1          507.0     17.27    60     662.0                   5.0   \n",
       "\n",
       "   funded_amnt  loan_amnt  tot_hi_cred_lim    dti  ...  home_improvement  \\\n",
       "0      32025.0    32025.0         210073.0  39.97  ...               0.0   \n",
       "1      11200.0    11200.0          97239.0  28.19  ...               0.0   \n",
       "2      20000.0    20000.0          32716.0  19.01  ...               0.0   \n",
       "3      10000.0    10000.0          14200.0   3.13  ...               0.0   \n",
       "4      11050.0    11050.0         245250.0   8.50  ...               0.0   \n",
       "\n",
       "   house  major_purchase  medical  moving  other  renewable_energy  \\\n",
       "0    0.0             0.0      0.0     0.0    0.0               0.0   \n",
       "1    0.0             0.0      0.0     0.0    0.0               0.0   \n",
       "2    0.0             0.0      0.0     0.0    0.0               0.0   \n",
       "3    0.0             0.0      0.0     0.0    0.0               0.0   \n",
       "4    0.0             0.0      0.0     0.0    0.0               0.0   \n",
       "\n",
       "   small_business  vacation  wedding  \n",
       "0             0.0       0.0      0.0  \n",
       "1             0.0       0.0      0.0  \n",
       "2             0.0       0.0      0.0  \n",
       "3             0.0       0.0      0.0  \n",
       "4             0.0       0.0      0.0  \n",
       "\n",
       "[5 rows x 79 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Importing clean data\n",
    "loan_df = pd.read_csv('C:\\\\Users\\\\hamid\\\\Desktop\\\\Capstone\\\\Data\\\\loan_sample_after_EDA.csv')\n",
    "\n",
    "loan_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "77a2a0f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(228958, 79)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loan_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b09b009",
   "metadata": {},
   "source": [
    "### Train-Test Split"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "472ad495",
   "metadata": {},
   "source": [
    "The first step in modeling is to seperate the dependent, y = `loan_status`, from all the independent variables, X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "86d14b23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seperating the dependent variable (y) from the independent variables (X)\n",
    "X = loan_df.drop(columns='loan_status')\n",
    "y = loan_df['loan_status']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "449b1a9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 228958 entries, 0 to 228957\n",
      "Data columns (total 78 columns):\n",
      " #   Column                 Non-Null Count   Dtype  \n",
      "---  ------                 --------------   -----  \n",
      " 0   last_fico_avg          228958 non-null  float64\n",
      " 1   int_rate               228958 non-null  float64\n",
      " 2   term                   228958 non-null  int64  \n",
      " 3   fico_avg               228958 non-null  float64\n",
      " 4   acc_open_past_24mths   228958 non-null  float64\n",
      " 5   funded_amnt            228958 non-null  float64\n",
      " 6   loan_amnt              228958 non-null  float64\n",
      " 7   tot_hi_cred_lim        228958 non-null  float64\n",
      " 8   dti                    228958 non-null  float64\n",
      " 9   inq_last_6mths         228958 non-null  float64\n",
      " 10  mo_sin_rcnt_tl         228958 non-null  float64\n",
      " 11  mo_sin_rcnt_rev_tl_op  228958 non-null  float64\n",
      " 12  mths_since_recent_bc   228958 non-null  float64\n",
      " 13  earliest_cr_line_year  228958 non-null  int64  \n",
      " 14  revol_util             228958 non-null  float64\n",
      " 15  annual_inc             228958 non-null  float64\n",
      " 16  mo_sin_old_il_acct     228958 non-null  float64\n",
      " 17  revol_bal              228958 non-null  float64\n",
      " 18  open_acc               228958 non-null  float64\n",
      " 19  issue_year             228958 non-null  int64  \n",
      " 20  pub_rec                228958 non-null  float64\n",
      " 21  application_type       228958 non-null  int64  \n",
      " 22  emp_length             228958 non-null  int64  \n",
      " 23  A1                     228958 non-null  float64\n",
      " 24  A2                     228958 non-null  float64\n",
      " 25  A3                     228958 non-null  float64\n",
      " 26  A4                     228958 non-null  float64\n",
      " 27  A5                     228958 non-null  float64\n",
      " 28  B1                     228958 non-null  float64\n",
      " 29  B2                     228958 non-null  float64\n",
      " 30  B3                     228958 non-null  float64\n",
      " 31  B4                     228958 non-null  float64\n",
      " 32  B5                     228958 non-null  float64\n",
      " 33  C1                     228958 non-null  float64\n",
      " 34  C2                     228958 non-null  float64\n",
      " 35  C3                     228958 non-null  float64\n",
      " 36  C4                     228958 non-null  float64\n",
      " 37  C5                     228958 non-null  float64\n",
      " 38  D1                     228958 non-null  float64\n",
      " 39  D2                     228958 non-null  float64\n",
      " 40  D3                     228958 non-null  float64\n",
      " 41  D4                     228958 non-null  float64\n",
      " 42  D5                     228958 non-null  float64\n",
      " 43  E1                     228958 non-null  float64\n",
      " 44  E2                     228958 non-null  float64\n",
      " 45  E3                     228958 non-null  float64\n",
      " 46  E4                     228958 non-null  float64\n",
      " 47  E5                     228958 non-null  float64\n",
      " 48  F1                     228958 non-null  float64\n",
      " 49  F2                     228958 non-null  float64\n",
      " 50  F3                     228958 non-null  float64\n",
      " 51  F4                     228958 non-null  float64\n",
      " 52  F5                     228958 non-null  float64\n",
      " 53  G1                     228958 non-null  float64\n",
      " 54  G2                     228958 non-null  float64\n",
      " 55  G3                     228958 non-null  float64\n",
      " 56  G4                     228958 non-null  float64\n",
      " 57  G5                     228958 non-null  float64\n",
      " 58  MORTGAGE               228958 non-null  float64\n",
      " 59  OTHER                  228958 non-null  float64\n",
      " 60  OWN                    228958 non-null  float64\n",
      " 61  RENT                   228958 non-null  float64\n",
      " 62  Not Verified           228958 non-null  float64\n",
      " 63  Source Verified        228958 non-null  float64\n",
      " 64  Verified               228958 non-null  float64\n",
      " 65  car                    228958 non-null  float64\n",
      " 66  credit_card            228958 non-null  float64\n",
      " 67  debt_consolidation     228958 non-null  float64\n",
      " 68  home_improvement       228958 non-null  float64\n",
      " 69  house                  228958 non-null  float64\n",
      " 70  major_purchase         228958 non-null  float64\n",
      " 71  medical                228958 non-null  float64\n",
      " 72  moving                 228958 non-null  float64\n",
      " 73  other                  228958 non-null  float64\n",
      " 74  renewable_energy       228958 non-null  float64\n",
      " 75  small_business         228958 non-null  float64\n",
      " 76  vacation               228958 non-null  float64\n",
      " 77  wedding                228958 non-null  float64\n",
      "dtypes: float64(73), int64(5)\n",
      "memory usage: 136.3 MB\n"
     ]
    }
   ],
   "source": [
    "X.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "bc8a5ef2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.series.Series'>\n",
      "RangeIndex: 228958 entries, 0 to 228957\n",
      "Series name: loan_status\n",
      "Non-Null Count   Dtype\n",
      "--------------   -----\n",
      "228958 non-null  int64\n",
      "dtypes: int64(1)\n",
      "memory usage: 1.7 MB\n"
     ]
    }
   ],
   "source": [
    "y.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b27ba60",
   "metadata": {},
   "source": [
    "Next step is to split the dataset into Training, Validation and Test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "6aa3d803",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import train_test_split\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, \n",
    "                                                      y, \n",
    "                                                      test_size = 0.2, \n",
    "                                                      random_state = 15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "5dd3b3a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The shape of the X_train dataframe is: (183166, 78).\n",
      "The shape of the X_test dataframe is: (45792, 78).\n",
      "\n",
      "The shape of the y_train dataframe is: (183166,).\n",
      "The shape of the y_test dataframe is: (45792,).\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# check dataframes shapes\n",
    "print(f\"The shape of the X_train dataframe is: {X_train.shape}.\")\n",
    "print(f\"The shape of the X_test dataframe is: {X_test.shape}.\\n\")\n",
    "print(f\"The shape of the y_train dataframe is: {y_train.shape}.\")\n",
    "print(f\"The shape of the y_test dataframe is: {y_test.shape}.\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65d54bab",
   "metadata": {},
   "source": [
    "### Scaling Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9c3b5f5",
   "metadata": {},
   "source": [
    "Now I am going to apply MinMaxScaler to the dataset. It is noted that the scaling is applied *after* train-test split to avoid data leakage i.e., the test data is not supposed to be exposed to MinMaxScaling at first. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "c039237c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "# apply MinMaxScaler()\n",
    "# instantiate the model\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "# fit the model\n",
    "scaler = scaler.fit(X_train)\n",
    "\n",
    "# transform\n",
    "X_train_scaled= scaler.transform(X_train)\n",
    "X_test_sclaed = scaler.transform(X_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bea4395",
   "metadata": {},
   "source": [
    "### Pipeline and Gridsearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "19653ec2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "db283766",
   "metadata": {},
   "outputs": [],
   "source": [
    "estimators = [('model', DecisionTreeClassifier())]\n",
    "\n",
    "pipe = Pipeline(estimators)\n",
    "\n",
    "param_grid = [\n",
    "    {'model': [DecisionTreeClassifier()],\n",
    "            'model__max_depth': [1, 4, 8],\n",
    "            'model__splitter':['best', 'random'],\n",
    "            'model__min_samples_leaf':[1,3, 5],\n",
    "            'model__max_features':['sqrt', 'log2']},       \n",
    "            {'model':[LogisticRegression(solver='saga')],\n",
    "            'model__C':[.01, 1, 100, 1e5],\n",
    "            'model__max_iter':[400],\n",
    "            'model__penalty':['l1', 'l2']}\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "a7b104fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid = GridSearchCV(pipe, param_grid, cv=5)\n",
    "fittedgrid = grid.fit(X_train_scaled, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "c8953480",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'model': LogisticRegression(C=1, max_iter=400, penalty='l1', solver='saga'),\n",
       " 'model__C': 1,\n",
       " 'model__max_iter': 400,\n",
       " 'model__penalty': 'l1'}"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fittedgrid.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "a178ffc5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8869671558350803"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fittedgrid.score(X_test_sclaed, y_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "boosting",
   "language": "python",
   "name": "boosting"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
